# Innf√∏ring i Big-O Notasjon

Big-O notasjon er et verkt√∏y vi bruker for √• beskrive **effektiviteten til algoritmer**. Den hjelper oss √• forst√• hvor raskt en algoritme vokser i forhold til st√∏rrelsen p√• dataene den behandler.

## Hvorfor Big-O?

N√•r vi vurderer en algoritme, er vi spesielt interessert i: - **Kj√∏retid (tidseffektivitet)** -- hvor raskt algoritmen kj√∏rer. - **Minnebruk (plasskompleksitet)** -- hvor mye minne algoritmen bruker.

I stedet for √• telle n√∏yaktige operasjoner, beskriver Big-O veksten **asymptotisk**, alts√• hvordan den oppf√∏rer seg n√•r datasettet blir veldig stort.

## Grunnid√©

- Vi ser p√• hvordan antall operasjoner √∏ker n√•r antall elementer `n` √∏ker.
- Sm√• detaljer (som konstanter og lavere ordens ledd) ignoreres.
- Vi fokuserer p√• det som betyr mest n√•r `n` blir stort.

Eksempel:\
Hvis en algoritme bruker `3n + 5` operasjoner, beskriver vi den som **O(n)**, fordi den vokser proporsjonalt med `n`.

## Vanlige kompleksitetsklasser

| Notasjon | Navn                | Beskrivelse                                    | Eksempel                           |
|----------|---------------------|------------------------------------------------|------------------------------------|
| O(1)     | Konstant tid        | Tar alltid like lang tid, uavhengig av datasettets st√∏rrelse | Tilgang til et element i et array |
| O(log n) | Logaritmisk tid     | Blir litt tregere n√•r `n` vokser, men vokser veldig sakte | Bin√¶rs√∏k |
| O(n)     | Line√¶r tid          | Vokser proporsjonalt med `n`                   | Line√¶rt s√∏k i en liste |
| O(n log n)| Line√¶r-logaritmisk tid | Vanlig i effektive sorteringsalgoritmer     | Quicksort, mergesort |
| O(n¬≤)    | Kvadratisk tid      | Vokser raskt, lite effektiv for store data     | Bubble sort, nested loops |
| O(2^n)   | Eksponentiell tid   | Ekstremt treg for store `n`                    | Brute force-l√∏sning av ‚Äúreisende selger‚Äù-problemet |
| O(n!)    | Faktoriell tid      | Blir praktisk talt umulig for selv sm√• `n`     | Generering av alle permutasjoner |

<div style="page-break-after:always;"></div>

## Eksempel p√• analyse

### Line√¶rt s√∏k (O(n))

``` python
def linear_search(lst, x):
    for item in lst:
        if item == x:
            return True
    return False
```

I verste fall m√• vi sjekke alle `n` elementene. Kompleksitet: **O(n)**.

### Bin√¶rs√∏k (O(log n))

``` python
def binary_search(lst, x):
    left, right = 0, len(lst) - 1
    while left <= right:
        mid = (left + right) // 2
        if lst[mid] == x:
            return True
        elif lst[mid] < x:
            left = mid + 1
        else:
            right = mid - 1
    return False
```

Hver gang deler vi listen i to. Antall steg vokser logaritmisk: **O(logn)**.

## Beste, verste og gjennomsnittlig tilfelle

N√•r vi analyserer algoritmer, ser vi ofte p√•:

- **Beste tilfelle**: raskest mulig (sjeldent nyttig).
- **Verste tilfelle**: det maksimale antall operasjoner. - **Gjennomsnittlig tilfelle**: forventet antall
operasjoner.

Eksempel:

- Line√¶rt s√∏k i en liste:
- Beste tilfelle: O(1) (elementet er f√∏rst).
- Verste tilfelle: O(n).
- Gjennomsnittlig tilfelle: O(n).

## Big-O vs.¬†andre notasjoner

- **Big-O**: √∏vre grense (worst case).\
- **Big-Œ© (Omega)**: nedre grense (best case).\
- **Big-Œò (Theta)**: eksakt vekstrate (n√•r b√•de √∏vre og nedre grense
    er lik).

Eksempel: Line√¶rt s√∏k har:\

- O(n) (√∏verste grense),\
- Œ©(1) (beste tilfelle),\
- Œò(n) (eksakt vekst i gjennomsnitt/verste fall).

## Oppsummering

- Big-O beskriver **hvor raskt en algoritme vokser** n√•r data blir store.
- Det hjelper oss √• sammenligne algoritmer uavhengig av maskinvare.
- Vi ignorerer konstanter og detaljer, og ser p√• hovedveksten.
- Kjennskap til vanlige kompleksitetsklasser (O(1), O(n), O(n log n), O(n¬≤)) er avgj√∏rende for √• lage effektive l√∏sninger.

------------------------------------------------------------------------

üëâ Med Big-O kan vi raskt avgj√∏re om en algoritme er praktisk for store
problemer, eller bare fungerer for sm√• datasett.
